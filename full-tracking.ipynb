{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online Tracking\n",
    "\n",
    "Given a list of images, we want to track players and the ball and gather their trajectories. Our model initializes several tracklets based on the detected boxes in the first image. In the following ones, the model links the boxes to the existing tracklets according to: \n",
    "\n",
    "1. their distance measured by the embedding model,\n",
    "2. their distance measured by boxes IoU's\n",
    "\n",
    "When the entire list of image is processed, we compute an homography for each image. We then apply each homography to the players coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install --user tensorflow==2.11.0\n",
    "# !pip3 install --user tensorflow-probability==0.19.0\n",
    "# !pip3 install --user dm-sonnet==2.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs\n",
    "\n",
    "Let's start by gathering a list of images: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: SM_FRAMEWORK=tf.keras\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "libcudnn.so.7: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f722e9bb49a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmxnet\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fut2/lib/python3.7/site-packages/mxnet/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\"\"\"MXNet: a concise, fast and flexible framework for deep learning.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mContext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcpu_pinned\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMXNetError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fut2/lib/python3.7/site-packages/mxnet/context.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassproperty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_metaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_MXClassPropertyMetaClass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_LIB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fut2/lib/python3.7/site-packages/mxnet/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;31m# library instance of mxnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m \u001b[0m_LIB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_lib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;31m# type definitions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fut2/lib/python3.7/site-packages/mxnet/base.py\u001b[0m in \u001b[0;36m_load_lib\u001b[0;34m()\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mlib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwinmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0x00000008\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m         \u001b[0mlib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRTLD_LOCAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m     \u001b[0;31m# DMatrix functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMXGetLastError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fut2/lib/python3.7/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: libcudnn.so.7: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "%env SM_FRAMEWORK=tf.keras\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import mxnet as mx\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"./narya\")\n",
    "\n",
    "from narya.utils.vizualization import visualize\n",
    "\n",
    "from narya.tracker.full_tracker import FootballTracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we initialize a 2d Field template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = cv2.imread('world_cup_template.png')\n",
    "template = cv2.cvtColor(template, cv2.COLOR_BGR2RGB)\n",
    "template = cv2.resize(template, (1280,720))\n",
    "template = template/255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then we create our list of images: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Images are ordered from 0 to 50:\n",
    "\"\"\"\n",
    "\n",
    "imgs_ordered = []\n",
    "for i in range(0,51):\n",
    "    path = 'test_img/img_fullLeicester 0 - [3] Liverpool.mp4_frame_full_' + str(i) + '.jpg'\n",
    "    imgs_ordered.append(path)\n",
    "    \n",
    "img_list = []\n",
    "for path in imgs_ordered:\n",
    "    if path.endswith('.jpg'):\n",
    "        image = cv2.imread(path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        img_list.append(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can vizualize the first image of our list: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_0,image_25,image_50 = img_list[0],img_list[25],img_list[50]\n",
    "print(\"Image shape: {}\".format(image_0.shape))\n",
    "visualize(image_0=image_0,\n",
    "            image_25=image_25,\n",
    "            image_50=image_50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Football Tracker\n",
    "\n",
    "We first need to create our tracker. This object gathers each and every one of our model: \n",
    "\n",
    "```python3\n",
    "class FootballTracker:\n",
    "\"\"\"Class for the full Football Tracker. Given a list of images, it allows to track and id each player as well as the ball.\n",
    "It also computes the homography at each given frame, and apply it to each player coordinates. \n",
    "\n",
    "Arguments:\n",
    "    pretrained: Boolean, if the homography and tracking models should be pretrained with our weights or not.\n",
    "    weights_homo: Path to weight for the homography model\n",
    "    weights_keypoints: Path to weight for the keypoints model\n",
    "    shape_in: Shape of the input image\n",
    "    shape_out: Shape of the ouput image\n",
    "    conf_tresh: Confidence treshold to keep tracked bouding boxes\n",
    "    track_buffer: Number of frame to keep in memory for tracking reIdentification\n",
    "    K: Number of boxes to keep at each frames\n",
    "    frame_rate: -\n",
    "Call arguments:\n",
    "    imgs: List of np.array (images) to track\n",
    "    split_size: if None, apply the tracking model to the full image. If its an int, the image shape must be divisible by this int.\n",
    "                We then split the image to create n smaller images of shape (split_size,split_size), and apply the model\n",
    "                to those.\n",
    "                We then reconstruct the full images and the full predictions.\n",
    "    results: list of previous results, to resume tracking\n",
    "    begin_frame: int, starting frame, if you want to resume tracking \n",
    "    verbose: Boolean, to display tracking at each frame or not\n",
    "    save_tracking_folder: Foler to save the tracking images\n",
    "    template: Football field, to warp it with the computed homographies on to the saved images\n",
    "    skip_homo: List of int. e.g.: [4,10] will not compute homography for frame 4 and 10, and reuse the computed homography\n",
    "                at frame 3 and 9.\n",
    "\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        pretrained=True,\n",
    "        weights_homo=None,\n",
    "        weights_keypoints=None,\n",
    "        shape_in=512.0,\n",
    "        shape_out=320.0,\n",
    "        conf_tresh=0.5,\n",
    "        track_buffer=30,\n",
    "        K=100,\n",
    "        frame_rate=30,\n",
    "    ):\n",
    "\n",
    "        self.player_ball_tracker = PlayerBallTracker(\n",
    "            conf_tresh=conf_tresh, track_buffer=track_buffer, K=K, frame_rate=frame_rate\n",
    "        )\n",
    "\n",
    "        self.homo_estimator = HomographyEstimator(\n",
    "            pretrained=pretrained,\n",
    "            weights_homo=weights_homo,\n",
    "            weights_keypoints=weights_keypoints,\n",
    "            shape_in=shape_in,\n",
    "            shape_out=shape_out,\n",
    "        )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = FootballTracker(frame_rate=24.7,track_buffer = 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now only have to call it on our list of images. We manually remove some failed homography estimation, at frame $\\in \\{25,...,30 \\}$ by adding ```skip_homo = [25,26,27,28,29,30]``` into our call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories = tracker(img_list,split_size = 512, save_tracking_folder = './test_outputs/',\n",
    "                        template = template,skip_homo = [25,26,27,28,29,30])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('trajectories.json', 'w') as outfile:\n",
    "    json.dump(trajectories, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the same images as before but with the tracking informations: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_ordered = []\n",
    "for i in range(0,51):\n",
    "    path = 'test_outputs/test_' + '{:05d}'.format(i) + '.jpg'\n",
    "\n",
    "    imgs_ordered.append(path)\n",
    "    \n",
    "img_list = []\n",
    "for path in imgs_ordered:\n",
    "    if path.endswith('.jpg'):\n",
    "        image = cv2.imread(path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        img_list.append(image)\n",
    "\n",
    "image_0,image_25,image_50 = img_list[0],img_list[25],img_list[50]\n",
    "print(\"Image shape: {}\".format(image_0.shape))\n",
    "visualize(image_0=image_0,\n",
    "            image_25=image_25,\n",
    "            image_50=image_50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also easily create a movie of the tracking data, and display it: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import progressbar\n",
    "with imageio.get_writer('test_outputs/movie.mp4', mode='I',fps=20) as writer:\n",
    "    for i in progressbar.progressbar(range(0,51)):\n",
    "        filename = 'test_outputs/test_{:05d}.jpg'.format(i)\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<div align=\"middle\">\n",
    "<video width=\"80%\" controls>\n",
    "      <source src=\"test_outputs/movie.mp4\" type=\"video/mp4\">\n",
    "</video></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Process trajectories \n",
    "\n",
    "We now have raw trajectories that we need to process. \n",
    "Fist, you can do several operations to ensure that the trajectories are good: \n",
    "\n",
    "* Delete an id at a certain frame\n",
    "* Delete an id from every frame\n",
    "* Merge two ids \n",
    "* Add an id at a given frame\n",
    "\n",
    "These operation are easy to do with some of our functions from ```narya.utils.tracker```: \n",
    "\n",
    "```python3\n",
    "def _remove_coords(traj, ids, frame):\n",
    "    \"\"\"Remove the x,y coordinates of an id at a given frame\n",
    "    Arguments:\n",
    "        traj: Dict mapping each id to a list of trajectory\n",
    "        ids: the id to target\n",
    "        frame: int, the frame we want to remove\n",
    "    Returns:\n",
    "        traj: Dict mapping each id to a list of trajectory\n",
    "    Raises:\n",
    "    \"\"\"\n",
    "    \n",
    "def _remove_ids(traj, list_ids):\n",
    "    \"\"\"Remove ids from a trajectory\n",
    "    Arguments:\n",
    "        traj: Dict mapping each id to a list of trajectory\n",
    "        list_ids: List of id\n",
    "    Returns:\n",
    "        traj: Dict mapping each id to a list of trajectory\n",
    "    Raises:\n",
    "    \"\"\"\n",
    "    \n",
    "def add_entity(traj, entity_id, entity_traj):\n",
    "    \"\"\"Adds a new id with a trajectory \n",
    "    Arguments:\n",
    "        traj: Dict mapping each id to a list of trajectory\n",
    "        entity_id: the id to add\n",
    "        entity_traj: the trajectory linked to entity_id we want to add\n",
    "    Returns:\n",
    "        traj: Dict mapping each id to a list of trajectory\n",
    "    Raises:\n",
    "    \"\"\"\n",
    "    \n",
    "def add_entity_coords(traj, entity_id, entity_traj, max_frame):\n",
    "    \"\"\"Add some coordinates to the trajectory of a given id\n",
    "    Arguments:\n",
    "        traj: Dict mapping each id to a list of trajectory\n",
    "        entity_id: the id to target\n",
    "        entity_traj: List of (x,y,frame) to add to the trajectory of entity_id\n",
    "        max_frame: int, the maximum number of frame in trajectories\n",
    "    Returns:\n",
    "        traj: Dict mapping each id to a list of trajectory\n",
    "    Raises:\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "def merge_id(traj, list_ids_frame):\n",
    "    \"\"\"Merge trajectories of different ids. \n",
    "    e.g.: (10,0,110),(12,110,300) will merge the trajectory of 10 between frame 0 and 110 to the \n",
    "        trajectory of 12 between frame 110 and 300.\n",
    "    Arguments:\n",
    "        traj: Dict mapping each id to a list of trajectory\n",
    "        list_ids_frame: List of (id,frame_start,frame_end)\n",
    "    Returns:\n",
    "        traj: Dict mapping each id to a list of trajectory\n",
    "    Raises:\n",
    "    \"\"\"\n",
    "    \n",
    "def merge_2_trajectories(traj1, traj2, id_mapper, max_frame_traj1):\n",
    "    \"\"\"Merge 2 dict of trajectories, if you want to merge the results of 2 tracking\n",
    "    Arguments:\n",
    "        traj1: Dict mapping each id to a list of trajectory\n",
    "        traj2: Dict mapping each id to a list of trajectory\n",
    "        id_mapper: A dict mapping each id in traj1 to id in traj2\n",
    "        max_frame_traj1: Maximum number of frame in the first trajectory\n",
    "    Returns:\n",
    "        traj1: Dict mapping each id to a list of trajectory\n",
    "    Raises:\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here, let's assume we don't have to perform any operations, and directly process our trajectoris into a Pandas Dataframe. \n",
    "\n",
    "First, we can save our raw trajectory with\n",
    "\n",
    "```python3\n",
    "import json\n",
    "\n",
    "with open('trajectories.json', 'w') as fp:\n",
    "    json.dump(trajectories, fp)\n",
    "```\n",
    "\n",
    "Let's start by padding our trajectories with np.nan and building a dict. for our dataframe: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('trajectories.json') as json_file:\n",
    "    trajectories = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from narya.utils.tracker import build_df_per_id\n",
    "\n",
    "df_per_id = build_df_per_id(trajectories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now fill the missing values, and apply a filter to smooth the trajectories: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from narya.utils.tracker import fill_nan_trajectories\n",
    "\n",
    "df_per_id = fill_nan_trajectories(df_per_id,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from narya.utils.tracker import get_full_results\n",
    "\n",
    "df = get_full_results(df_per_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trajectory Dataframe\n",
    "\n",
    "We now have access to a dataframe with for each id, for each frame, the 2D coordinates of the entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, this you can save this dataframe using ```df.to_csv('results_df.csv')```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "narya",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "4f6566de871839d199b40fcc370dffd84f09060ed43c010187679a1243d61e3a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
